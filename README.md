# --
بصير
# ✨ مشروع بصير | Basir

🎯 **فكرة المشروع**  
"بصير" هو مشروع تطبيقي ذكي طُوّر خلال فترة التدريب، يهدف إلى تمكين تواصل بسيط وسلس بين الصمّ والمكفوفين باستخدام الذكاء الاصطناعي.  
يعتمد على التعرف على إشارات اليد (مثل H و I) وتحويلها إلى كلمة منطوقة تُعرض في واجهة مخصّصة للمكفوفين.

---

## 🧠 الأدوات والتقنيات المستخدمة

### 1. Teachable Machine by Google  
أداة بسيطة عبر المتصفح لتدريب نماذج تعلم الآلة بسهولة.  
- تم استخدامها لتدريب النموذج على تمييز إشارات اليد (H و I).
- بعد التدريب، تم تصدير النموذج بصيغة TensorFlow.

🔗 [رابط Teachable Machine](https://teachablemachine.withgoogle.com/)

### 2. OpenCV  
مكتبة لمعالجة الصور والفيديوهات.  
- استخدمت لفتح الكاميرا وتتبع حركة اليد في الوقت الحقيقي.
- تم ربطها مع النموذج لتوقع الإشارة مباشرة من الكاميرا.

### 3. TensorFlow / Keras  
- مكتبة تعلم آلة لتحميل وتشغيل النموذج المدرب (H5 أو SavedModel).
- استخدمت لتحليل الصور القادمة من الكاميرا وتوقع الإشارة.

### 4. gTTS (Google Text-to-Speech)  
- لتحويل الكلمة الناتجة إلى صوت مسموع للمكفوفين.

### 5. Flask  
- لإنشاء واجهة ويب بسيطة تجمع بين التعرف على الإشارة وعرض الكلمة صوتيًا.

---

## 📁 محتويات المشروع

- `app.py` – ملف تشغيل الواجهة والربط بين الكاميرا والنموذج والصوت.
- `predict_sign.py` – اختبار النموذج مباشرة بدون واجهة.
- `keras_model.h5` أو `model.savedmodel` – النموذج المدرب.
- `labels.txt` – أسماء الفئات (H و I).
- `templates/` – تحتوي على صفحات HTML للواجهة.
- `static/` – مجلد للملفات الثابتة مثل CSS أو JS.
- `result.mp3` – الصوت الناتج عن الكلمة "Hi".

---

## 🎯 أهداف المشروع

- ربط الصمّ بالمكفوفين بطريقة بسيطة وسهلة.
- تمكين المكفوف من "سماع" ما يشير إليه الأصم بلغة الإشارة.
- عرض الذكاء الاصطناعي كوسيلة لخدمة الوصول الشامل.

---

## 🙏 شكرًا لـ [اسم الجهة التدريبية]  
على إتاحة هذه الفرصة والدعم في تطوير هذا المشروع.

---

## 🧵 الهاشتاقات  
`#AIforGood` `#TeachableMachine` `#OpenCV` `#Accessibility` `#MachineLearning` `#TrainingProject` `#بصير`

---
